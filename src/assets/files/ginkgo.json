{
    "title": "Computer Vision Based Solution to Nano-liter Liquid Dispenses Quality Control",
    "link": "https://github.com/amoebacodes/GinkgoCapstone/tree/main/package_draft",
    "summary": "Collaboration with the Automation Team at Ginkgo Bioworks",
    "description": "In a team of four, we provided Ginkgo with three different computer vision algorithms to detect nano-liter level magnetic bead dispenses from the Echo liquid handler, as a quality control (QC) measure for next-generation sequencing (NGS) library prep. Given a picture of a 384-well plate, our package can detect and report the locations of bead dispenses. Our solutions include two tranditional computer vision (intensity-based) algorithms and one deep learning model (multilayer perceptron). We received weekly feedback from Ginkgo's Automation team and presented our package to the NGS and Automation teams. \n \nMy personal contribution includes developing and improving one of the traditional computer vision algorithms (adaptive thresholding), implementing image registration, and documenting, cleaning up and packaging the code. The adaptive thresholding method achieved comparable results with the deep learning model (both having F1 scores of around 0.98) , and I am pleased to see a simple solution work as well as a complicated one. \n \nFor detailed description of methods and results, please review the README file in the source code page.",
    "tags": ["Computer Vision", "Software Development", "Automation"]
}